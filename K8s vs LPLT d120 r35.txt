=== RUNNING HYPOTHESIS TEST ===
Hypothesis: LPLT reduces power consumption vs K8s baseline, but increases response times

=== POWER CONSUMPTION COMPARISON ===
Kubernetes average power: 3.1W
LPLT average power: 3.0W
Power savings: 0.2%

=== PERFORMANCE COMPARISON (ROBUST METRICS) ===
Kubernetes MEDIAN response time: 1064.169s
LPLT MEDIAN response time: 1160.234s
MEDIAN performance penalty: 9.0%
Kubernetes 95th percentile: 25186.153s
LPLT 95th percentile: 25185.127s
95th percentile penalty: -0.0%
Kubernetes warm-up avg: 5975.703s
LPLT warm-up avg: 6591.003s
Warm-up performance penalty: 10.3%

=== WAIT TIME ANALYSIS ===
K8s median wait time: 0.000s
LPLT median wait time: 0.000s
Wait time improvement: nan%

=== REVISED HYPOTHESIS RESULT ===
âœ… HYPOTHESIS CONFIRMED (MEDIAN): LPLT saves 0.2% energy
   at the cost of 9.0% slower median response times
ðŸ” DEEP ANALYSIS: Understanding Why LPLT Outperforms K8s

=== NODE DISTRIBUTION ANALYSIS ===
K8s uses 120 unique nodes
LPLT uses 120 unique nodes
Node spreading difference: 0

K8s node load distribution:
  Average replicas per node: 14.0
  Max replicas on one node: 32
  Min replicas on one node: 4

LPLT node load distribution:
  Average replicas per node: 12.9
  Max replicas on one node: 22
  Min replicas on one node: 7

Consolidation factor: 0.92
âž¡ï¸ Similar distribution patterns
=== COLD START ANALYSIS ===
K8s scheduling success rate: 0.6982142857142857
LPLT scheduling success rate: 0.6795774647887324

Cold start execution times:
K8s early median t_exec: 3.325s
LPLT early median t_exec: 3.306s
âœ… LPLT has 0.6% faster cold starts

Total scheduling events:
K8s: 1681 scheduling events
LPLT: 1706 scheduling events
=== WORKLOAD-SPECIFIC PERFORMANCE ===

resnet50-inference (12616 vs 12607 samples):
  Median: K8s=0.707s, LPLT=0.766s (+8.3%)
  P95: K8s=5.835s, LPLT=5.604s (-4.0%)

fio (3850 vs 4306 samples):
  Median: K8s=158.823s, LPLT=152.620s (-3.9%)
  P95: K8s=473.959s, LPLT=464.978s (-1.9%)

speech-inference (2458 vs 2458 samples):
  Median: K8s=3.813s, LPLT=3.810s (-0.1%)
  P95: K8s=43.891s, LPLT=43.891s (+0.0%)

python-pi (15335 vs 15329 samples):
  Median: K8s=0.923s, LPLT=0.926s (+0.4%)
  P95: K8s=49.333s, LPLT=49.334s (+0.0%)

resnet50-training (196 vs 197 samples):
  Median: K8s=307.578s, LPLT=308.237s (+0.2%)
  P95: K8s=502.876s, LPLT=511.177s (+1.7%)
=== SCALING DECISION ANALYSIS ===
K8s scaling actions:
  Scale up: 390
  Scale down: 169
  No action: 163
  Total actions: 559

LPLT scaling actions:
  Scale up: 386
  Scale down: 8
  No action: 330
  Total actions: 394

High response time events (>1s):
K8s: 31 events
LPLT: 33 events

Node type selection frequency:
K8s preferences:
  nuc: 195
  coral: 158
  nx: 37
LPLT preferences:
  nano: 194
  coral: 154
  nx: 38
=== RESOURCE CONTENTION ANALYSIS ===
K8s average utilization by node type:
           cpu_util  memory_util
node_type                       
coral      0.011950     0.009959
nano       0.016825     0.012619
nuc        0.022083     0.018402
nx         0.022963     0.016534
rockpi     0.028970     0.024142
rpi3       0.024964     0.020803

LPLT average utilization by node type:
           cpu_util  memory_util
node_type                       
coral      0.011950     0.009959
nano       0.016825     0.012619
nuc        0.022083     0.018402
nx         0.022963     0.016534
rockpi     0.025989     0.021658
rpi3       0.024083     0.020069

High CPU utilization events (>90%):
K8s: 0 events
LPLT: 0 events

Average power per active node:
K8s: 3.05W
LPLT: 3.05W

==================================================
HYPOTHESIS VALIDATION SUMMARY
==================================================
âœ… H2: LPLT has faster cold start performance
âœ… H3: LPLT scales more conservatively (less churn)

=== SUMMARY ===
Trade-off ratio: 0.2% energy savings for 9.0% performance cost
Plot saved as tradeoff_plot.png
